{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a9ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from time import time\n",
    "\n",
    "directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1),  (1, 0), (1, 1)]\n",
    "directions_array = np.array(directions)\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_word = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_word = True\n",
    "\n",
    "    def search(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "        return node.is_word\n",
    "\n",
    "    def starts_with(self, prefix):\n",
    "        node = self.root\n",
    "        for char in prefix:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "        return True\n",
    "\n",
    "trie = Trie()\n",
    "with open('dictionary_actual_game.txt', 'r') as file:\n",
    "    for word in file.read().splitlines():\n",
    "        trie.insert(word)\n",
    "        \n",
    "keys = list(string.ascii_lowercase)\n",
    "score = [1,3,3,2,1,4,2,4,3,8,5,5,3,2,1,3,10,1,1,1,2,4,4,8,4,10]\n",
    "letter_to_int = dict(zip(keys, range(1, 27)))\n",
    "letter_to_int[\"N\"] = 0\n",
    "\n",
    "dictionary_df = pd.read_csv(\"dictionary_df2.csv\")\n",
    "dictionary_df.loc[160413, \"word\"] = \"null\"\n",
    "dictionary_df.loc[154353, \"word\"] = \"nan\"\n",
    "dictionary_df = dictionary_df[dictionary_df.columns[1:]]\n",
    "score_dict = dict(zip(dictionary_df[\"word\"], dictionary_df[\"score\"]))\n",
    "\n",
    "def tiles_remove(tiles, board):\n",
    "    board[tiles[:, 0], tiles[:, 1]] = \"N\"\n",
    "    return board\n",
    "\n",
    "def gravity(board_1):\n",
    "    # Gravity down\n",
    "    row_index, col_index = np.where(board_1 == \"N\")\n",
    "    indices = list(zip(row_index, col_index))\n",
    "    for r, c in indices:\n",
    "        column = board_1[:r + 1, c].copy()\n",
    "        if r > 0:\n",
    "            column[1:] = column[:-1]\n",
    "            column[0] = \"N\"\n",
    "        board_1[:r + 1, c] = column\n",
    "    # Gravity right\n",
    "    row_index, col_index = np.where(board_1 == \"N\")\n",
    "    indices = list(zip(row_index, col_index))\n",
    "    for r, c in indices:\n",
    "        row = board_1[r, :c + 1].copy()\n",
    "        if c > 0:\n",
    "            row[1:] = row[:-1]\n",
    "            row[0] = \"N\"\n",
    "        board_1[r, :c + 1] = row\n",
    "    return board_1\n",
    "\n",
    "class WordSoup_state:\n",
    "    def __init__(self, board, S=0, word_lst=[], depth=0):\n",
    "        self.board = board\n",
    "        self.score = S\n",
    "        self.word_lst = word_lst\n",
    "        self.depth = depth\n",
    "        self.board_array = np.array(board)\n",
    "\n",
    "    def get_legal_actions(self):\n",
    "        rows, cols = len(self.board), len(self.board[0])\n",
    "        result = []\n",
    "\n",
    "        def dfs(i, j, path, indices, visited, node):\n",
    "            if node.is_word:\n",
    "                result.append((path, indices))  # Store the word and its indices\n",
    "            for dx, dy in directions:\n",
    "                x, y = i + dx, j + dy\n",
    "                if 0 <= x < rows and 0 <= y < cols and (x, y) not in visited:\n",
    "                    char = self.board[x][y]\n",
    "                    if char in node.children:\n",
    "                        visited.add((x, y))\n",
    "                        dfs(x, y, path + char, indices + [(x, y)], visited, node.children[char])\n",
    "                        visited.remove((x, y))\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                char = self.board[i][j]\n",
    "                if char in trie.root.children:\n",
    "                    dfs(i, j, char, [(i, j)], {(i, j)}, trie.root.children[char])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def is_game_over(self):\n",
    "        found_words = self.get_legal_actions()\n",
    "        if len(found_words) > 0:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def game_result(self, Score):\n",
    "        if self.score >= Score:\n",
    "            return 1\n",
    "        return -1\n",
    "\n",
    "    def move(self, action):\n",
    "        word, indices = action\n",
    "        _ = tiles_remove(np.array(indices), self.board_array.copy())\n",
    "        new_board = gravity(_)\n",
    "        new_score = self.score + score_dict[word]\n",
    "        if np.sum(new_board != \"N\") == 0:\n",
    "            new_score += 500\n",
    "        new_board = new_board.tolist()\n",
    "        new_word_lst = self.word_lst.copy()\n",
    "        new_word_lst.append(word)\n",
    "\n",
    "        return WordSoup_state(new_board, new_score, new_word_lst, self.depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af78368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExhaustiveSearch(state, step=1):\n",
    "    L = 0\n",
    "    for l in state.board:\n",
    "        for i in l:\n",
    "            L+=1\n",
    "    untried_actions = state.get_legal_actions()\n",
    "    untried_actions_sorted = sorted(untried_actions, key=lambda x: score_dict[x[0]], reverse=True)\n",
    "    best_score_so_far = score_dict[untried_actions_sorted[0][0]]\n",
    "    best_ = []\n",
    "    for action in untried_actions_sorted:\n",
    "        if score_dict[action[0]]==best_score_so_far:\n",
    "            best_.append(action)\n",
    "        else:\n",
    "            break\n",
    "    result = [state.move(action) for action in best_]\n",
    "    if step == 1:\n",
    "        return result\n",
    "    else:\n",
    "        queue = [state.move(action) for action in untried_actions_sorted]\n",
    "        best = []\n",
    "    \n",
    "    while queue:\n",
    "        state = queue.pop(0)\n",
    "        y = best_score_so_far - state.score\n",
    "        untried_actions = state.get_legal_actions()\n",
    "        if len(untried_actions) == 0:\n",
    "            continue\n",
    "        length = 0\n",
    "        for l in state.board:\n",
    "            for i in l:\n",
    "                if i != \"N\":\n",
    "                    break\n",
    "                length+=1\n",
    "        \n",
    "        def Score_Cal(x):\n",
    "            if len(x[0])==(L-length):\n",
    "                return score_dict[x[0]]+500\n",
    "            else:\n",
    "                return score_dict[x[0]]\n",
    "        untried_actions_sorted = sorted(untried_actions, key=lambda x: Score_Cal(x), reverse=True)\n",
    "        s_ = Score_Cal(untried_actions_sorted[0])\n",
    "        if s_ > y:\n",
    "            best_score_so_far = state.score + s_\n",
    "            best = []\n",
    "            for x in untried_actions_sorted:\n",
    "                if Score_Cal(x)==s_:\n",
    "                    best.append((state, x))\n",
    "                else:\n",
    "                    break\n",
    "        if state.depth < step - 1:\n",
    "            _ = [state.move(action) for action in untried_actions_sorted]\n",
    "            if _:\n",
    "                queue = _ + queue\n",
    "            else:\n",
    "                continue\n",
    "    if best:\n",
    "        result = [state.move(action) for state, action in best]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553875c",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "\n",
    "Code here are created by generative AI and we cite it here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c0514",
   "metadata": {},
   "source": [
    "### Feature extractions (standardized)\n",
    "state (partial board):\n",
    "1. board length\n",
    "2. occurrence of letters\n",
    "3. board liberity\n",
    "\n",
    "action (word):\n",
    "1. word length\n",
    "2. number of vowels\n",
    "3. occurrence of letters\n",
    "4. score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38d16aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_liberty(board):\n",
    "    b = board.copy()\n",
    "    rows, columns = b.shape\n",
    "    row, col = np.where(b == \"N\")\n",
    "    NE = set(zip(row, col))\n",
    "    row, col = np.where(b != \"N\")\n",
    "    E = list(zip(row, col))\n",
    "    \n",
    "    total_liberty = 0\n",
    "    for r, c in E:\n",
    "        neighbors = directions_array + np.array([r, c])\n",
    "        valid_neighbors = neighbors[\n",
    "            (neighbors[:, 0] >= 0) & (neighbors[:, 0] < rows) &\n",
    "            (neighbors[:, 1] >= 0) & (neighbors[:, 1] < columns)\n",
    "        ]\n",
    "        total_liberty += sum(tuple(pos) not in NE for pos in valid_neighbors)\n",
    "    \n",
    "    return total_liberty\n",
    "\n",
    "def Feature_Selection(state, action):\n",
    "    board_array = np.array(state.board)\n",
    "    word, indices = action\n",
    "    word_array = np.array(list(word))\n",
    "    \n",
    "    board_length = np.count_nonzero(board_array != \"N\")\n",
    "    occ_board = [np.count_nonzero(board_array == l) / board_length for l in string.ascii_lowercase]\n",
    "    liberty = count_liberty(board_array) / 742\n",
    "    \n",
    "    word_length = len(word)\n",
    "    num_vowels = sum(1 for char in word if char in 'aeiou') / word_length\n",
    "    occ_word = [np.count_nonzero(word_array == l) / word_length for l in string.ascii_lowercase]\n",
    "    word_score = score_dict[word] / 1475\n",
    "    \n",
    "    return np.array([board_length / 108] + occ_board + [liberty] +\n",
    "                    [word_length / 25] + [num_vowels] + occ_word + [word_score])\n",
    "\n",
    "def q_value(theta, features):\n",
    "    return np.dot(theta, features)\n",
    "\n",
    "def epsilon_greedy_policy(state, theta, epsilon=0.1):\n",
    "    actions = state.get_legal_actions()\n",
    "    if not actions:\n",
    "        return None\n",
    "\n",
    "    if np.random.rand() < epsilon:\n",
    "        return actions[np.random.choice(len(actions))]\n",
    "\n",
    "    values = [(action, q_value(theta, Feature_Selection(state, action))) for action in actions]\n",
    "    return max(values, key=lambda x: x[1])[0]\n",
    "\n",
    "def q_learning_update(theta, state, action, next_state, reward, alpha=0.01, gamma=1.0):\n",
    "    features = Feature_Selection(state, action)\n",
    "\n",
    "    if next_state.is_game_over():\n",
    "        target = reward\n",
    "    else:\n",
    "        next_actions = next_state.get_legal_actions()\n",
    "        if not next_actions:\n",
    "            target = reward\n",
    "        else:\n",
    "            next_values = [q_value(theta, Feature_Selection(next_state, a)) for a in next_actions]\n",
    "            target = reward + gamma * max(next_values)\n",
    "\n",
    "    prediction = q_value(theta, features)\n",
    "    td_error = target - prediction\n",
    "    theta += alpha * td_error * features\n",
    "    return theta\n",
    "\n",
    "def train_q_learning(initial_board, episodes=1000, alpha=0.01, gamma=1.0, epsilon=0.1, decay=False):\n",
    "    theta = np.random.randn(57)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = WordSoup_state(initial_board.copy())\n",
    "        step = 0\n",
    "        while not state.is_game_over():\n",
    "            action = epsilon_greedy_policy(state, theta, epsilon)\n",
    "            if action is None:\n",
    "                break\n",
    "\n",
    "            next_state = state.move(action)\n",
    "            reward = score_dict[action[0]]\n",
    "            if np.count_nonzero(next_state.board_array != \"N\") == 0:\n",
    "                reward += 500\n",
    "\n",
    "            theta = q_learning_update(theta, state, action, next_state, reward, alpha, gamma)\n",
    "            state = next_state\n",
    "            step += 1\n",
    "\n",
    "        if decay:\n",
    "            epsilon = max(0.01, epsilon * 0.995)\n",
    "\n",
    "        if (ep + 1) % 50 == 0:\n",
    "            print(f\"Episode {ep + 1}: epsilon={epsilon:.4f}\")\n",
    "\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2bba77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = [\n",
    "    ['p', 'i', 'g'],\n",
    "    ['c', 'a', 't'],\n",
    "    ['d', 'o', 'g']\n",
    "]\n",
    "initial_state = WordSoup_state(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73779fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50: epsilon=0.1000\n",
      "Episode 100: epsilon=0.1000\n",
      "Episode 150: epsilon=0.1000\n",
      "Episode 200: epsilon=0.1000\n",
      "Episode 250: epsilon=0.1000\n",
      "Episode 300: epsilon=0.1000\n",
      "Episode 350: epsilon=0.1000\n",
      "Episode 400: epsilon=0.1000\n",
      "Episode 450: epsilon=0.1000\n",
      "Episode 500: epsilon=0.1000\n",
      "Episode 550: epsilon=0.1000\n",
      "Episode 600: epsilon=0.1000\n",
      "Episode 650: epsilon=0.1000\n",
      "Episode 700: epsilon=0.1000\n",
      "Episode 750: epsilon=0.1000\n",
      "Episode 800: epsilon=0.1000\n",
      "Episode 850: epsilon=0.1000\n",
      "Episode 900: epsilon=0.1000\n",
      "Episode 950: epsilon=0.1000\n",
      "Episode 1000: epsilon=0.1000\n",
      "Episode 1050: epsilon=0.1000\n",
      "Episode 1100: epsilon=0.1000\n",
      "Episode 1150: epsilon=0.1000\n",
      "Episode 1200: epsilon=0.1000\n",
      "Episode 1250: epsilon=0.1000\n",
      "Episode 1300: epsilon=0.1000\n",
      "Episode 1350: epsilon=0.1000\n",
      "Episode 1400: epsilon=0.1000\n",
      "Episode 1450: epsilon=0.1000\n",
      "Episode 1500: epsilon=0.1000\n",
      "Episode 1550: epsilon=0.1000\n",
      "Episode 1600: epsilon=0.1000\n",
      "Episode 1650: epsilon=0.1000\n",
      "Episode 1700: epsilon=0.1000\n",
      "Episode 1750: epsilon=0.1000\n",
      "Episode 1800: epsilon=0.1000\n",
      "Episode 1850: epsilon=0.1000\n",
      "Episode 1900: epsilon=0.1000\n",
      "Episode 1950: epsilon=0.1000\n",
      "Episode 2000: epsilon=0.1000\n",
      "Episode 2050: epsilon=0.1000\n",
      "Episode 2100: epsilon=0.1000\n",
      "Episode 2150: epsilon=0.1000\n",
      "Episode 2200: epsilon=0.1000\n",
      "Episode 2250: epsilon=0.1000\n",
      "Episode 2300: epsilon=0.1000\n",
      "Episode 2350: epsilon=0.1000\n",
      "Episode 2400: epsilon=0.1000\n",
      "Episode 2450: epsilon=0.1000\n",
      "Episode 2500: epsilon=0.1000\n",
      "Episode 2550: epsilon=0.1000\n",
      "Episode 2600: epsilon=0.1000\n",
      "Episode 2650: epsilon=0.1000\n",
      "Episode 2700: epsilon=0.1000\n",
      "Episode 2750: epsilon=0.1000\n",
      "Episode 2800: epsilon=0.1000\n",
      "Episode 2850: epsilon=0.1000\n",
      "Episode 2900: epsilon=0.1000\n",
      "Episode 2950: epsilon=0.1000\n",
      "Episode 3000: epsilon=0.1000\n",
      "Episode 3050: epsilon=0.1000\n",
      "Episode 3100: epsilon=0.1000\n",
      "Episode 3150: epsilon=0.1000\n",
      "Episode 3200: epsilon=0.1000\n",
      "Episode 3250: epsilon=0.1000\n",
      "Episode 3300: epsilon=0.1000\n",
      "Episode 3350: epsilon=0.1000\n",
      "Episode 3400: epsilon=0.1000\n",
      "Episode 3450: epsilon=0.1000\n",
      "Episode 3500: epsilon=0.1000\n",
      "Episode 3550: epsilon=0.1000\n",
      "Episode 3600: epsilon=0.1000\n",
      "Episode 3650: epsilon=0.1000\n",
      "Episode 3700: epsilon=0.1000\n",
      "Episode 3750: epsilon=0.1000\n",
      "Episode 3800: epsilon=0.1000\n",
      "Episode 3850: epsilon=0.1000\n",
      "Episode 3900: epsilon=0.1000\n",
      "Episode 3950: epsilon=0.1000\n",
      "Episode 4000: epsilon=0.1000\n",
      "Episode 4050: epsilon=0.1000\n",
      "Episode 4100: epsilon=0.1000\n",
      "Episode 4150: epsilon=0.1000\n",
      "Episode 4200: epsilon=0.1000\n",
      "Episode 4250: epsilon=0.1000\n",
      "Episode 4300: epsilon=0.1000\n",
      "Episode 4350: epsilon=0.1000\n",
      "Episode 4400: epsilon=0.1000\n",
      "Episode 4450: epsilon=0.1000\n",
      "Episode 4500: epsilon=0.1000\n",
      "Episode 4550: epsilon=0.1000\n",
      "Episode 4600: epsilon=0.1000\n",
      "Episode 4650: epsilon=0.1000\n",
      "Episode 4700: epsilon=0.1000\n",
      "Episode 4750: epsilon=0.1000\n",
      "Episode 4800: epsilon=0.1000\n",
      "Episode 4850: epsilon=0.1000\n",
      "Episode 4900: epsilon=0.1000\n",
      "Episode 4950: epsilon=0.1000\n",
      "Episode 5000: epsilon=0.1000\n",
      "Episode 5050: epsilon=0.1000\n",
      "Episode 5100: epsilon=0.1000\n",
      "Episode 5150: epsilon=0.1000\n",
      "Episode 5200: epsilon=0.1000\n",
      "Episode 5250: epsilon=0.1000\n",
      "Episode 5300: epsilon=0.1000\n",
      "Episode 5350: epsilon=0.1000\n",
      "Episode 5400: epsilon=0.1000\n",
      "Episode 5450: epsilon=0.1000\n",
      "Episode 5500: epsilon=0.1000\n",
      "Episode 5550: epsilon=0.1000\n",
      "Episode 5600: epsilon=0.1000\n",
      "Episode 5650: epsilon=0.1000\n",
      "Episode 5700: epsilon=0.1000\n",
      "Episode 5750: epsilon=0.1000\n",
      "Episode 5800: epsilon=0.1000\n",
      "Episode 5850: epsilon=0.1000\n",
      "Episode 5900: epsilon=0.1000\n",
      "Episode 5950: epsilon=0.1000\n",
      "Episode 6000: epsilon=0.1000\n",
      "Episode 6050: epsilon=0.1000\n",
      "Episode 6100: epsilon=0.1000\n",
      "Episode 6150: epsilon=0.1000\n",
      "Episode 6200: epsilon=0.1000\n",
      "Episode 6250: epsilon=0.1000\n",
      "Episode 6300: epsilon=0.1000\n",
      "Episode 6350: epsilon=0.1000\n",
      "Episode 6400: epsilon=0.1000\n",
      "Episode 6450: epsilon=0.1000\n",
      "Episode 6500: epsilon=0.1000\n",
      "Episode 6550: epsilon=0.1000\n",
      "Episode 6600: epsilon=0.1000\n",
      "Episode 6650: epsilon=0.1000\n",
      "Episode 6700: epsilon=0.1000\n",
      "Episode 6750: epsilon=0.1000\n",
      "Episode 6800: epsilon=0.1000\n",
      "Episode 6850: epsilon=0.1000\n",
      "Episode 6900: epsilon=0.1000\n",
      "Episode 6950: epsilon=0.1000\n",
      "Episode 7000: epsilon=0.1000\n",
      "Episode 7050: epsilon=0.1000\n",
      "Episode 7100: epsilon=0.1000\n",
      "Episode 7150: epsilon=0.1000\n",
      "Episode 7200: epsilon=0.1000\n",
      "Episode 7250: epsilon=0.1000\n",
      "Episode 7300: epsilon=0.1000\n",
      "Episode 7350: epsilon=0.1000\n",
      "Episode 7400: epsilon=0.1000\n",
      "Episode 7450: epsilon=0.1000\n",
      "Episode 7500: epsilon=0.1000\n",
      "Episode 7550: epsilon=0.1000\n",
      "Episode 7600: epsilon=0.1000\n",
      "Episode 7650: epsilon=0.1000\n",
      "Episode 7700: epsilon=0.1000\n",
      "Episode 7750: epsilon=0.1000\n",
      "Episode 7800: epsilon=0.1000\n",
      "Episode 7850: epsilon=0.1000\n",
      "Episode 7900: epsilon=0.1000\n",
      "Episode 7950: epsilon=0.1000\n",
      "Episode 8000: epsilon=0.1000\n",
      "Episode 8050: epsilon=0.1000\n",
      "Episode 8100: epsilon=0.1000\n",
      "Episode 8150: epsilon=0.1000\n",
      "Episode 8200: epsilon=0.1000\n",
      "Episode 8250: epsilon=0.1000\n",
      "Episode 8300: epsilon=0.1000\n",
      "Episode 8350: epsilon=0.1000\n",
      "Episode 8400: epsilon=0.1000\n",
      "Episode 8450: epsilon=0.1000\n",
      "Episode 8500: epsilon=0.1000\n",
      "Episode 8550: epsilon=0.1000\n",
      "Episode 8600: epsilon=0.1000\n",
      "Episode 8650: epsilon=0.1000\n",
      "Episode 8700: epsilon=0.1000\n",
      "Episode 8750: epsilon=0.1000\n",
      "Episode 8800: epsilon=0.1000\n",
      "Episode 8850: epsilon=0.1000\n",
      "Episode 8900: epsilon=0.1000\n",
      "Episode 8950: epsilon=0.1000\n",
      "Episode 9000: epsilon=0.1000\n",
      "Episode 9050: epsilon=0.1000\n",
      "Episode 9100: epsilon=0.1000\n",
      "Episode 9150: epsilon=0.1000\n",
      "Episode 9200: epsilon=0.1000\n",
      "Episode 9250: epsilon=0.1000\n",
      "Episode 9300: epsilon=0.1000\n",
      "Episode 9350: epsilon=0.1000\n",
      "Episode 9400: epsilon=0.1000\n",
      "Episode 9450: epsilon=0.1000\n",
      "Episode 9500: epsilon=0.1000\n",
      "Episode 9550: epsilon=0.1000\n",
      "Episode 9600: epsilon=0.1000\n",
      "Episode 9650: epsilon=0.1000\n",
      "Episode 9700: epsilon=0.1000\n",
      "Episode 9750: epsilon=0.1000\n",
      "Episode 9800: epsilon=0.1000\n",
      "Episode 9850: epsilon=0.1000\n",
      "Episode 9900: epsilon=0.1000\n",
      "Episode 9950: epsilon=0.1000\n",
      "Episode 10000: epsilon=0.1000\n",
      "CPU times: user 4min 10s, sys: 10.8 s, total: 4min 21s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "theta = train_q_learning(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ccdce583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(state, theta):\n",
    "    actions = state.get_legal_actions()\n",
    "    if not actions:\n",
    "        return None\n",
    "\n",
    "    best_action = None\n",
    "    best_value = -float('inf')\n",
    "\n",
    "    for action in actions:\n",
    "        features = Feature_Selection(state, action)\n",
    "        value = q_value(theta, features)\n",
    "        if value > best_value:\n",
    "            best_value = value\n",
    "            best_action = action\n",
    "\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18b5c539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('oca', [(2, 1), (1, 0), (1, 1)])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = greedy_policy(initial_state, theta)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f1e1ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dipt', [(2, 0), (2, 1), (1, 1), (1, 2)])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_state = initial_state.move(a)\n",
    "greedy_policy(second_state, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c9981738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01037236e+00,  1.67011406e+01, -7.35071228e-01,  1.92661339e+01,\n",
       "        4.44040946e+00,  2.50228746e-01,  3.97600300e-01, -3.43370907e+00,\n",
       "        4.16545215e-01,  5.52904096e+01,  1.36177769e+00,  3.66747331e-01,\n",
       "        1.36206331e+00, -1.14302789e+00,  3.11185241e+00,  2.56836612e+01,\n",
       "        7.18909256e+00, -3.28915842e-01, -3.81950960e-02, -8.71895389e-01,\n",
       "        1.25921782e+01,  5.74665384e-02,  9.62221678e-01,  4.29382528e-01,\n",
       "        8.30820778e-01, -9.13803767e-01,  1.85254428e-02,  3.78641359e+00,\n",
       "        1.98289893e+01,  2.50735457e+01,  1.72472980e+01,  7.23377969e-02,\n",
       "        2.26511773e+01,  2.05323084e+01, -1.55597008e+00,  3.81261414e-01,\n",
       "        2.09141384e+01, -1.93285732e+00, -2.19837311e+00, -1.59423997e+00,\n",
       "        6.05048964e-03, -6.08585031e-01,  6.78933710e-01,  1.15973649e+00,\n",
       "        9.45286174e+00,  2.52554928e+01, -7.69424747e-01, -5.56702308e-01,\n",
       "       -2.41667774e-01,  2.07523605e+01, -1.25622900e-01,  2.56414921e-01,\n",
       "       -4.32617838e-01,  8.06544546e-02,  5.14825453e-01,  7.54537347e-01,\n",
       "        3.20908833e+00])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db3c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict[\"booked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e9d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
